{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas\n",
    "import time\n",
    "#import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "#import scipy.stats\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = np.genfromtxt('qsar_fish_toxicity.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6 molecular descriptors and 1 quantitative experimental response:\n",
    "1) CIC0\n",
    "2) SM1_Dz(Z)\n",
    "3) GATS1i\n",
    "4) NdsCH\n",
    "5) NdssC\n",
    "6) MLOGP\n",
    "7) quantitative response, LC50 [-LOG(mol/L)]\n",
    "\n",
    "The linear regression model is given by LC50 = $\\alpha_1$CIC0 + $\\alpha_2$SM1_Dz(Z) + $\\alpha_3$GATS1i + $\\alpha_4$MLOGP + β\n",
    "\n",
    "## 1) sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 1-4:\n",
      "[ 0.44750162  1.22068139 -0.77463965  0.38310065]\n",
      "beta:\n",
      "2.1943526381758227\n"
     ]
    }
   ],
   "source": [
    "X = my_data[:,[0,1,2,5]]\n",
    "y = my_data[:,6]\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print('alpha 1-4:')\n",
    "print(reg.coef_)\n",
    "print('beta:')\n",
    "print(reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) explicit formula\n",
    "We have the model\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{y} = \\mathbf{X}\\mathbf{\\alpha} + \\mathbf{\\epsilon}\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "    1 & x_{11}       & x_{12} & x_{13} & x_{14} \\\\\n",
    "    1 & x_{21}       & x_{22} & x_{23} & x_{24} \\\\\n",
    "    ... & ... & ... & ... & ...\\\\\n",
    "    1 & x_{n1}       & x_{n2} & x_{n3} & x_{n4}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "The first column corresponds to the constant term, and 2nd to 5th column correponds to CIC0, SM1_Dz(Z), GATS1i and MLOGP. The row corresponds to observations. \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{\\alpha} = \\begin{bmatrix}\n",
    "\\beta \\\\\n",
    "\\alpha_1 \\\\\n",
    "\\alpha_2 \\\\\n",
    "\\alpha_3 \\\\\n",
    "\\alpha_4\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{\\epsilon} = \\begin{bmatrix}\n",
    "\\epsilon_1 \\\\\n",
    "\\epsilon_2 \\\\\n",
    "... \\\\\n",
    "\\epsilon_n\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "The goal is to find $\\tilde{\\alpha}$ to minimize squared error $\\sum_i^n \\epsilon_i^2 = \\epsilon'\\epsilon  = (\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha})'(\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha})$\n",
    "\n",
    "By matrix calculus, $\\frac{ \\partial {(\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha})'(\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha})}}{\\partial{\\mathbf{\\alpha}} } = 2(\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha})'(-\\mathbf{X})$\n",
    "\n",
    "To find the minimum, we need to let $\\frac{ \\partial {(\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha})'(\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha})}}{\\partial{\\mathbf{\\alpha}} } = 0$, and we have $(\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha})'\\mathbf{X} = 0$\n",
    "\n",
    "Transpose it, we have $\\mathbf{X}'(\\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha}) = 0$\n",
    "\n",
    "To solve the optimal $\\tilde{\\alpha}$, we have $\\mathbf{X}'\\mathbf{y} = \\mathbf{X}'\\mathbf{X}\\tilde{\\alpha}$\n",
    "\n",
    "Therefore, $\\tilde{\\alpha} = (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{y}$\n",
    "\n",
    "\n",
    "https://en.wikipedia.org/wiki/Matrix_calculus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.ones(len(y))\n",
    "X1 = np.reshape(X1, (len(y), 1))\n",
    "X = np.array(X)\n",
    "X_new = np.hstack((X1,X))\n",
    "\n",
    "y = np.reshape(y, (len(y), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_left = np.linalg.inv(np.matmul(X_new.transpose(), X_new))\n",
    "alpha_right = np.matmul(X_new.transpose(), y)\n",
    "alpha = np.matmul(alpha_left, alpha_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 1-4:\n",
      "[[ 0.44750162]\n",
      " [ 1.22068139]\n",
      " [-0.77463965]\n",
      " [ 0.38310065]]\n",
      "beta\n",
      "[2.19435264]\n"
     ]
    }
   ],
   "source": [
    "print('alpha 1-4:')\n",
    "print(alpha[1:])\n",
    "print('beta')\n",
    "print(alpha[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) gradient descent method\n",
    "Recall the notation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{\\epsilon} = \\begin{bmatrix}\n",
    "\\epsilon_1 \\\\\n",
    "\\epsilon_2 \\\\\n",
    "... \\\\\n",
    "\\epsilon_n\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \\begin{bmatrix}\n",
    "    1 & x_{11}       & x_{12} & x_{13} & x_{14} \\\\\n",
    "    1 & x_{21}       & x_{22} & x_{23} & x_{24} \\\\\n",
    "    ... & ... & ... & ... & ...\\\\\n",
    "    1 & x_{n1}       & x_{n2} & x_{n3} & x_{n4}\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "The algorithm for gradient descent is:\n",
    "1) initialize with a coeffient matrix $\\mathbf{\\alpha_0}$\n",
    "\n",
    "2) calculate the errors:\n",
    "\\begin{equation*}\n",
    "\\epsilon = \\mathbf{y} - \\mathbf{X}\\mathbf{\\alpha_i}\n",
    "\\end{equation*}\n",
    "\n",
    "3) calculate the gradient:\n",
    "\\begin{equation*}\n",
    "D\\Lambda(\\mathbf{\\alpha_i}) = −\\frac{2}{N} \\epsilon'\\mathbf{X}\n",
    "\\end{equation*}\n",
    "\n",
    "4) update the coeffient matrix:\n",
    "\\begin{equation*}\n",
    "\\mathbf{\\alpha_{i+1}} = \\mathbf{\\alpha_i} - D\\Lambda(\\mathbf{\\alpha_i})\n",
    "\\end{equation*}\n",
    "\n",
    "repeat (2)(3)(4) until the change in squared error $\\epsilon'\\epsilon$ is smaller than a predefined value (here we set it to $10^{-7}$)\n",
    "\n",
    "### initializing with all 1 coefficient matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    if (change>0):\\n        alpha_0 = alpha_1;\\n    else:\\n        print(alpha_1)\\n        alpha_0 = alpha_0; \\n        break;\\n'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.reshape(y, (len(y), 1))\n",
    "\n",
    "delta = 0.02\n",
    "\n",
    "#initialize the coefficient matrix\n",
    "alpha_0 = np.ones(5)\n",
    "alpha_0 = np.reshape(alpha_0, (5,1))\n",
    "\n",
    "change = 1e10\n",
    "\n",
    "while change > 1e-5:\n",
    "    #calculate residue vector\n",
    "    epsilon_0 = np.subtract(y, np.matmul(X_new, alpha_0))\n",
    "    \n",
    "    #calcualte gradient\n",
    "    gradient = -2/len(y)*np.matmul(epsilon_0.transpose(), X_new)\n",
    "    \n",
    "    #update coefficient matrix\n",
    "    alpha_1 = alpha_0 - delta*np.reshape(gradient, (5,1))\n",
    "    \n",
    "    #calculate the residue vector for new coefficient \n",
    "    epsilon_1 = np.subtract(y, np.matmul(X_new, alpha_1))\n",
    "    \n",
    "    #calculate change in squared error\n",
    "    change = np.inner(epsilon_0.transpose(),epsilon_0.transpose()) - np.inner(epsilon_1.transpose(),epsilon_1.transpose())\n",
    "\n",
    "    alpha_0 = alpha_1;\n",
    "'''\n",
    "    if (change>0):\n",
    "        alpha_0 = alpha_1;\n",
    "    else:\n",
    "        print(alpha_1)\n",
    "        alpha_0 = alpha_0; \n",
    "        break;\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 1-4:\n",
      "[[ 0.44903569]\n",
      " [ 1.22319641]\n",
      " [-0.7705289 ]\n",
      " [ 0.38344126]]\n",
      "beta\n",
      "[2.18194711]\n"
     ]
    }
   ],
   "source": [
    "print('alpha 1-4:')\n",
    "print(alpha_0[1:])\n",
    "print('beta')\n",
    "print(alpha_0[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
